{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project was made using spark in order to be the foundation of building a datawarhouse having the start schema architecture using Python and Spark. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import re\n",
    "import pandas as pd\n",
    "from cleaner import Cleaner\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The main scope of this project is to enrich the 194 immigration dataset with supplemntry dataset in order to broad our analysis and deepen our understanding from the data\n",
    "\n",
    "#### Expolring the data with Pandas as a start\n",
    "\n",
    "##### 194 SAS Immigration Dataset\n",
    "This data comes from the US National tourism and Trade office."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "df_194_sample = pd.read_csv('immigration_data_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'STU', 'PHA', 'OTH'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_194_sample['occup'].unique()\n",
    "#df_194_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HHW', 'MCA', 'OGG', 'LOS', 'CHM', 'ATL', 'SFR', 'NYC', 'CHI',\n",
       "       'PHI', 'FTL', 'BOS', 'SAI', 'NAS', 'SEA', 'ORL', 'PSP', 'HOU',\n",
       "       'NEW', 'BAL', 'SNJ', 'DET', 'AGA', 'LVG', 'MIA', 'SDP', 'VCV',\n",
       "       'DUB', 'PEM', 'TAM', 'BLA', 'WAS', 'KOA', 'DAL', 'SHA', 'SPM',\n",
       "       'NIA', 'PHR', 'MIL', 'SLC', 'CLT', 'EPI', 'SNA', 'MON', 'DLR',\n",
       "       'SFB', 'OPF', 'X96', 'CLM', 'LIH', 'DEN', 'PHO', 'POO', 'NOL',\n",
       "       'WPB', 'PBB', 'TOR', 'MAA', 'RNO', 'FMY', 'HIG', 'OAK', 'OTM',\n",
       "       'ONT', 'SRQ', 'LLB', 'NCA', 'SUM', 'STR', 'HAM'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_194_sample['i94port'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_194_full = pd.read_sas('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_194_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid       float64\n",
       "i94yr       float64\n",
       "i94mon      float64\n",
       "i94cit      float64\n",
       "i94res      float64\n",
       "i94port      object\n",
       "arrdate     float64\n",
       "i94mode     float64\n",
       "i94addr      object\n",
       "depdate     float64\n",
       "i94bir      float64\n",
       "i94visa     float64\n",
       "count       float64\n",
       "dtadfile     object\n",
       "visapost     object\n",
       "occup        object\n",
       "entdepa      object\n",
       "entdepd      object\n",
       "entdepu      object\n",
       "matflag      object\n",
       "biryear     float64\n",
       "dtaddto      object\n",
       "gender       object\n",
       "insnum       object\n",
       "airline      object\n",
       "admnum      float64\n",
       "fltno        object\n",
       "visatype     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like some datatypes needs to be casted properly \n",
    "df_194_full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3096313\n",
       "Name: i94port, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_194_full['i94port'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['XXX', 'ATL', 'WAS', 'NYC', 'TOR', 'BOS', 'HOU', 'MIA', 'CHI',\n",
       "       'LOS', 'CLT', 'DEN', 'DAL', 'DET', 'NEW', 'FTL', 'LVG', 'ORL',\n",
       "       'NOL', 'PIT', 'SFR', 'SPM', 'POO', 'PHI', 'SEA', 'SLC', 'TAM',\n",
       "       'HAM', 'NAS', 'VCV', 'MAA', 'AUS', 'HHW', 'OGG', 'PHO', 'SDP',\n",
       "       'SFB', 'EDA', 'MON', 'CLG', 'DUB', 'FMY', 'YGF', 'SAJ', 'CIN',\n",
       "       'BAL', 'RDU', 'WPB', 'STT', 'OAK', 'NSV', 'SNA', 'OTT', 'X96',\n",
       "       '5KE', 'CLE', 'HAR', 'PSP', 'CHR', 'HAL', 'SAA', 'KOA', 'SHA',\n",
       "       'WIN', 'BGM', 'NCA', 'OPF', 'SAI', 'JFA', 'AGA', 'ONT', 'CLM',\n",
       "       'STL', 'W55', 'CHS', 'SNJ', 'SRQ', 'ANC', 'LNB', 'LIH', 'MIL',\n",
       "       'INP', 'KAN', 'ROC', 'SAC', 'BRO', 'LAR', 'RNO', 'SGR', 'ELP',\n",
       "       'MCA', 'MDT', 'SPE', 'FPR', 'SYR', 'ICT', 'MLB', 'ADS', 'TUC',\n",
       "       'DLR', 'CAE', 'CHA', 'HSV', 'WIL', 'HPN', 'HEF', 'BRG', 'BED',\n",
       "       'DAB', 'JAC', 'FRB', 'SWF', 'KEY', 'PTK', 'MWH', 'X44', 'MYR',\n",
       "       'APF', 'ATW', 'PVD', 'BUF', 'PIE', 'MHT', 'BDL', 'NYL', 'VNY',\n",
       "       '5T6', 'LEX', 'NOR', 'BQN', 'MEM', 'INT', 'CRQ', 'SPO', 'FOK',\n",
       "       'PEV', 'FAR', 'MAF', 'TKI', 'OMA', 'LOU', 'PHF', 'RST', 'MMU',\n",
       "       'CPX', 'SCH', 'RYY', 'PEM', 'JKM', 'LYN', 'OGD', 'NC8', 'MOB',\n",
       "       'SAV', 'HIG', 'CHL', 'WLL', 'MTH', 'AXB', 'SUM', 'ADW', 'SGJ',\n",
       "       'JMZ', 'BLA', 'SSM', 'YIP', 'EPI', 'GSP', 'BHX', 'MND', 'FCA',\n",
       "       'CRP', 'YHC', 'PHU', 'COB', 'OTM', 'STR', 'PSM', 'FWA', 'SYS',\n",
       "       'PEN', 'ABQ', 'HEL', 'DPA', 'CHM', 'EGP', 'POR', 'PIR', 'ORO',\n",
       "       'LUK', 'DER', 'DOU', 'SWE', 'NOO', 'LAN', 'VIC', 'COO', 'NRN',\n",
       "       'REN', 'HTM', 'HID', 'BEL', 'CLS', 'PRO', 'PRE', 'PCF', 'RIF',\n",
       "       'ROS', 'PAR', 'BEE', 'DAC', 'NOG', 'BTN', 'DNS', 'NAC', 'GAL',\n",
       "       'FPT', 'ABG', 'MAS', 'PTL', 'TEC', 'ROO', 'BAU', 'FRI', 'TRO',\n",
       "       'ANA', 'FRE', 'AND', 'LEW', 'NIA', 'PBB', 'THO', 'YSL', 'BEB',\n",
       "       'DLB', 'DNA', 'FTC', 'GPM', 'LAU', 'LCB', 'LLB', 'MOO', 'NEC',\n",
       "       'PHR', 'ROU', 'SKA', 'WHO', 'ANZ', 'BOA', 'CAL', 'MAD', 'MOR',\n",
       "       'ROM', 'WBE', 'AGN', 'CNA', 'SLU', 'FER', 'ALC', 'MET', 'PDN',\n",
       "       'PNH', 'VIB', 'WAL', 'BWA', 'CHT', 'DVL', 'FRT', 'HNN', 'HNS',\n",
       "       'HVR', 'SJO', 'WAR', 'COL', 'TUR', 'ABS', 'BWM', 'CNC', 'RAY',\n",
       "       'VCB', 'MGM', 'MRC', 'PGR', 'LOI', 'ADT', 'NRG', 'CRY', 'ERC',\n",
       "       'FTF', 'FTK', 'SHR', 'MAI', 'NIG', 'NRT', 'VNB', 'FAL', 'LUB',\n",
       "       'RIO', 'LWT'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_194_full['i94port'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3096313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many duplicate values do we have\n",
    "# this will give us a sense later on the size of the issue we have in our main dataset\n",
    "df_194_full.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it seems that we have a large number of duplicate values in comparison to the size of the dataset\n",
    "#df_194_full.isna().sum()\n",
    "df_194_full['cicid'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### World Temperature Data:\n",
    "This dataset came from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.read_csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt                                    0\n",
       "AverageTemperature               364130\n",
       "AverageTemperatureUncertainty    364130\n",
       "City                                  0\n",
       "Country                               0\n",
       "Latitude                              0\n",
       "Longitude                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets see how many NA values do we have in our world temperature dataset\n",
    "df_temp.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    8599212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Duplicate value counts\n",
    "df_temp.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Denmark', 'Turkey', 'Kazakhstan', 'China', 'Spain', 'Germany',\n",
       "       'Nigeria', 'Iran', 'Russia', 'Canada', \"Côte D'Ivoire\",\n",
       "       'United Kingdom', 'Saudi Arabia', 'Japan', 'United States', 'India',\n",
       "       'Benin', 'United Arab Emirates', 'Mexico', 'Venezuela', 'Ghana',\n",
       "       'Ethiopia', 'Australia', 'Yemen', 'Indonesia', 'Morocco',\n",
       "       'Pakistan', 'France', 'Libya', 'Burma', 'Brazil', 'South Africa',\n",
       "       'Syria', 'Egypt', 'Algeria', 'Netherlands', 'Malaysia', 'Portugal',\n",
       "       'Ecuador', 'Italy', 'Uzbekistan', 'Philippines', 'Madagascar',\n",
       "       'Chile', 'Belgium', 'El Salvador', 'Romania', 'Peru', 'Colombia',\n",
       "       'Tanzania', 'Tunisia', 'Turkmenistan', 'Israel', 'Eritrea',\n",
       "       'Paraguay', 'Greece', 'New Zealand', 'Vietnam', 'Cameroon', 'Iraq',\n",
       "       'Afghanistan', 'Argentina', 'Azerbaijan', 'Moldova', 'Mali',\n",
       "       'Congo (Democratic Republic Of The)', 'Thailand',\n",
       "       'Central African Republic', 'Bosnia And Herzegovina', 'Bangladesh',\n",
       "       'Switzerland', 'Equatorial Guinea', 'Cuba', 'Lebanon', 'Mozambique',\n",
       "       'Serbia', 'Angola', 'Somalia', 'Norway', 'Nepal', 'Poland',\n",
       "       'Ukraine', 'Guinea Bissau', 'Malawi', 'Burkina Faso', 'Slovakia',\n",
       "       'Congo', 'Belarus', 'Gambia', 'Czech Republic', 'Hungary',\n",
       "       'Burundi', 'Zimbabwe', 'Bulgaria', 'Haiti', 'Puerto Rico',\n",
       "       'Sri Lanka', 'Nicaragua', 'Zambia', 'Honduras', 'Taiwan', 'Bolivia',\n",
       "       'Guinea', 'Ireland', 'Senegal', 'Latvia', 'Qatar', 'Albania',\n",
       "       'Tajikistan', 'Kenya', 'Guatemala', 'Finland', 'Sierra Leone',\n",
       "       'Sweden', 'Botswana', 'Guyana', 'Austria', 'Uganda', 'Armenia',\n",
       "       'Dominican Republic', 'Jordan', 'Djibouti', 'Sudan', 'Lithuania',\n",
       "       'Rwanda', 'Jamaica', 'Togo', 'Macedonia', 'Cyprus', 'Gabon',\n",
       "       'Slovenia', 'Bahrain', 'Swaziland', 'Niger', 'Lesotho', 'Liberia',\n",
       "       'Uruguay', 'Chad', 'Bahamas', 'Mauritania', 'Panama', 'Suriname',\n",
       "       'Cambodia', 'Montenegro', 'Mauritius', 'Papua New Guinea',\n",
       "       'Iceland', 'Croatia', 'Reunion', 'Oman', 'Costa Rica',\n",
       "       'South Korea', 'Hong Kong', 'Singapore', 'Estonia', 'Georgia',\n",
       "       'Mongolia', 'Laos', 'Namibia'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47555</th>\n",
       "      <td>1820-01-01</td>\n",
       "      <td>2.101</td>\n",
       "      <td>3.217</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47556</th>\n",
       "      <td>1820-02-01</td>\n",
       "      <td>6.926</td>\n",
       "      <td>2.853</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47557</th>\n",
       "      <td>1820-03-01</td>\n",
       "      <td>10.767</td>\n",
       "      <td>2.395</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47558</th>\n",
       "      <td>1820-04-01</td>\n",
       "      <td>17.989</td>\n",
       "      <td>2.202</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47559</th>\n",
       "      <td>1820-05-01</td>\n",
       "      <td>21.809</td>\n",
       "      <td>2.036</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "47555  1820-01-01               2.101                          3.217  Abilene   \n",
       "47556  1820-02-01               6.926                          2.853  Abilene   \n",
       "47557  1820-03-01              10.767                          2.395  Abilene   \n",
       "47558  1820-04-01              17.989                          2.202  Abilene   \n",
       "47559  1820-05-01              21.809                          2.036  Abilene   \n",
       "\n",
       "             Country Latitude Longitude  \n",
       "47555  United States   32.95N   100.53W  \n",
       "47556  United States   32.95N   100.53W  \n",
       "47557  United States   32.95N   100.53W  \n",
       "47558  United States   32.95N   100.53W  \n",
       "47559  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp[df_temp['Country'] == 'United States'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US Cities Demographics Data\n",
    "This data comes from OpenSoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# delimitier here is a \";\"\n",
    "df_demog = pd.read_csv('us-cities-demographics.csv',delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City                       object\n",
       "State                      object\n",
       "Median Age                float64\n",
       "Male Population           float64\n",
       "Female Population         float64\n",
       "Total Population            int64\n",
       "Number of Veterans        float64\n",
       "Foreign-born              float64\n",
       "Average Household Size    float64\n",
       "State Code                 object\n",
       "Race                       object\n",
       "Count                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Types looks like they are correct\n",
    "df_demog.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average Household Size    16\n",
       "Foreign-born              13\n",
       "Number of Veterans        13\n",
       "Female Population          3\n",
       "Male Population            3\n",
       "Count                      0\n",
       "Race                       0\n",
       "State Code                 0\n",
       "Total Population           0\n",
       "Median Age                 0\n",
       "State                      0\n",
       "City                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets seet how many null values do we have in each column\n",
    "df_demog.isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count                     0\n",
       "Race                      0\n",
       "State Code                0\n",
       "Average Household Size    0\n",
       "Foreign-born              0\n",
       "Number of Veterans        0\n",
       "Total Population          0\n",
       "Female Population         0\n",
       "Male Population           0\n",
       "Median Age                0\n",
       "State                     0\n",
       "City                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it seems that the if we execlude the NA average household size, other NAs will be exluded too.\n",
    "df_demog[df_demog['Average Household Size'].isna() == False].isna().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141554272"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog['Count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_194 = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3096313 28\n"
     ]
    }
   ],
   "source": [
    "#shape of the dataset\n",
    "print(df_194.count(),len(df_194.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "#df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "The data cleaning tasks for the three datasets are consolidated in the cleaner.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary of valid i94port codes\n",
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "i94port_valid = {}\n",
    "with open('i94port_valid.txt') as f:\n",
    "     for line in f:\n",
    "         match = re_obj.search(line)\n",
    "         i94port_valid[match[1]]=[match[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def get_i94port(city):\n",
    "    '''\n",
    "    Input: City name\n",
    "    \n",
    "    Output: Corresponding i94port\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for key in i94port_valid:\n",
    "        if city.lower() in i94port_valid[key][0].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#reading the demograohic and tempreture datasets with spark\n",
    "df_temp = spark.read.format('csv').option('header','true').load('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "df_demog = spark.read.format('csv').option('header','true').option('delimiter',';').load('us-cities-demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: integer (nullable = true)\n",
      " |-- i94mon: integer (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: integer (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- data_base_sas: date (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Performing cleaning tasks here\n",
    "df_194_cleaned = Cleaner.clean_194_dataset(df_194,i94port_valid)\n",
    "df_temp_cleaned = Cleaner.clean_temp_dataset(df_temp)\n",
    "df_demog_cleaned = Cleaner.clean_demographic_dataset(df_demog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(port_city_dict)\n",
    "\n",
    "#df_temp_cleaned.select('City').distinct().show()\n",
    "df_temp_cleaned = df_temp_cleaned.withColumn('port_code',get_i94port(df_temp_cleaned.City))\n",
    "df_demog_cleaned = df_demog_cleaned.withColumn('port_code',get_i94port(df_demog_cleaned.City))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- median_age: string (nullable = true)\n",
      " |-- male_population: string (nullable = true)\n",
      " |-- female_population: string (nullable = true)\n",
      " |-- total_population: string (nullable = true)\n",
      " |-- number_of_veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- average_household_size: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      " |-- port_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demog_cleaned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "##### Fact Table\n",
    "    The Fact table is going to be consisted of columns from the immigration dataset joind with the tempreture data.\n",
    "    \n",
    "    *cicid will act as our primary key\n",
    "    *i94yr (renamed as  year during the cleaning process)\n",
    "    *i94mon (renamed as month during the cleaning process)\n",
    "    *i94port (renamed as port_code during the cleaning process)\n",
    "    *arrdate (renamed as arrival_date during the cleaning process)\n",
    "    *depdate (renamed as departure_date during the cleaning process)\n",
    "    *AverageTemperature\n",
    "    *average_household_size\n",
    "    *number_of_veterans        \n",
    "    *total_population          \n",
    "    *female_population         \n",
    "    *male_population           \n",
    "    *median_Age \n",
    "\n",
    "##### Dimension Table 1 (dim_supp_info) \n",
    "    This table contains supplementrey info from the main immigration dataset.\n",
    "      *cicid will act as our primary key \n",
    "      *biryear (Renamed as birthday_year during the cleaning process)\n",
    "      *gender\n",
    "      *airline\n",
    "      *fltno   (Renamed as flight_Number during the cleaning process)\n",
    "      *visatype\n",
    "\n",
    "##### Dimension Table 2 (dim_cities_info)\n",
    "       *port_code (created based on the get_port_code UDF function)\n",
    "       *City\n",
    "       *Country\n",
    "       *Latitude\n",
    "       *Longitude\n",
    "\n",
    "    \n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "     * Load the 194 immigration datset\n",
    "     * Load the world temprature dataset\n",
    "     * Load the Demographics dataset\n",
    "     * Clean the 194 immigration datset\n",
    "     * Clean the world temprature dataset\n",
    "     * Clean the Demographics dataset\n",
    "     * Create the fact table\n",
    "     * Create the Supp_Info dimension table\n",
    "     * Create the temperature dimension table\n",
    "     * Create the demographics dimension table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model.\n",
    "##### Create the fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#register the three dataframes as SQL views\n",
    "df_194_cleaned.createOrReplaceTempView('immigration_data')\n",
    "df_temp_cleaned.createOrReplaceTempView('temperature_data')\n",
    "df_demog_cleaned.createOrReplaceTempView('demographics_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_immig_fact = spark.sql(\"\"\"\n",
    "\n",
    "SELECT cicid \n",
    "year ,\n",
    "month,\n",
    "imm.port_code ,\n",
    "arrival_date ,\n",
    "departure_date,\n",
    "temp.average_temperature,\n",
    "demog.average_household_size,\n",
    "demog.number_of_veterans, \n",
    "demog.total_population ,   \n",
    "demog.female_population,    \n",
    "demog.male_population,     \n",
    "demog.median_Age \n",
    "\n",
    "FROM immigration_data imm\n",
    "JOIN temperature_data temp ON imm.port_code = temp.port_code\n",
    "JOIN demographics_dataset demog ON imm.state_code = demog.state_code AND imm.port_code = demog.port_code\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create the second dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_supp_info = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  cicid, \n",
    "  birthday_year,\n",
    "  gender,\n",
    "  airline,\n",
    "  flight_number,\n",
    "  visatype,\n",
    "  state_code\n",
    "  \n",
    "FROM immigration_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Create the third dimension table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_cities_info = spark.sql(\"\"\" \n",
    "SELECT \n",
    "port_code,\n",
    "City,\n",
    "Country,\n",
    "Latitude,\n",
    "Longitude\n",
    "from temperature_data\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks & Model Validation\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def exists_data_quality_check(df_table,table_name):\n",
    "    \n",
    "    if df_table.count() > 0:\n",
    "        print(\"Data quality check has passed for table {}\".format(table_name))\n",
    "    else:\n",
    "        print(\"Data quality check has passed for table {}\".format(table_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def data_integrity_checks(df_table,table_name):\n",
    "    \n",
    "    if table_name == 'Dim_Supp_Info':\n",
    "        # validate state codes\n",
    "       integrity_supp_info = df_immig_fact.select('state_code').distinct().join(df_supp_info,df_immig_fact['state_code'] ==\n",
    "                                                         df_supp_info['state_code'],'left_anti' ).count() ==0\n",
    "    \n",
    "       if integrity_supp_info == False:\n",
    "            print('Data integrity check failed on column state_code in table {}'.format(table_name))\n",
    "        \n",
    "       else:\n",
    "            \n",
    "            print('Data integrity check passed on column state_code in table {}'.format(table_name))\n",
    "\n",
    "\n",
    "    elif table_name == 'Dim_Cities_Info':\n",
    "        integrity_cities_ingo = df_immig_fact.select('port_code').distinct().join(df_cities_info,df_immig_fact['port_code'] ==\n",
    "                                                         df_supp_info['port_code'],'left_anti' ).count() == 0\n",
    "      \n",
    "        if integrity_cities_ingo == False:\n",
    "            print('Data integrity check failed on column port_code in table {}'.format(table_name))\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            print('Data integrity check passed on column port_code in table {}'.format(table_name))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3490, 5)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "exists_data_quality_check(df_immig_fact,'Fact_Immigration')\n",
    "exists_data_quality_check(df_supp_info,'Dim_Supp_Info')\n",
    "exists_data_quality_check(df_cities_info,'Dim_Cities_Info')\n",
    "\n",
    "\n",
    "data_integrity_checks(df_supp_info,'Dim_Supp_Info')\n",
    "data_integrity_checks(df_cities_info,'Dim_Cities_Info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "df_sample_query  = df_immig_fact.join(df_cities_info,df_immig_fact['port_code'] ==\n",
    "                                                         df_supp_info['port_code'],'left' ).join()(df_supp_info,df_immig_fact['state_code'] ==\n",
    "                                                         df_supp_info['state_code'],'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Fact Table\n",
    "    The Fact table is going to be consisted of columns from the immigration dataset joind with the tempreture data.\n",
    "    \n",
    "    *cicid : primary key\n",
    "    *year : numeric year\n",
    "    *month : numeric month\n",
    "    *port_code :3 character code based on the city name \n",
    "    *arrival_date : arrival date\n",
    "    *departure_date : departure data\n",
    "    *average_temperature : average temperature of the destination city \n",
    "    *average_household_size : average household size in the destination city.\n",
    "    *number_of_veterans : number of veterans in the destination city        \n",
    "    *total_population : total population in the destination city \n",
    "    *female_population : total female population in the destination city.         \n",
    "    *male_population : total male population in the destination city.          \n",
    "    *median_Age : Median age in the destination city. \n",
    "\n",
    "##### Dimension Table 1 (dim_supp_info) \n",
    "    This table contains supplementrey info from the main immigration dataset.\n",
    "      *cicid : Primary Key\n",
    "      *birthday_year : birthday year\n",
    "      *gender :gender\n",
    "      *airline : airline used\n",
    "      *flight_number : flight_number\n",
    "      *visatype : reason for immigration\n",
    "\n",
    "##### Dimension Table 2 (dim_cities_info)\n",
    "       *port_code :3 character code based on the city name \n",
    "       *City : city name\n",
    "       *Country \" country name\n",
    "       *Latitude : latitude of the city\n",
    "       *Longitude : longitude of the city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* The main technology used in this project is Apache Spark or more precisely the python API for Apache Spark (PySpark). Spark is a great choice big data analysis and its highly sclabale. For the data model , i went with a star schema architecture where there is one gact table and 2 dimension tables as its straighforward and statisfies the needs for this project.\n",
    "\n",
    "* The update frequencey mainly depend on the velocity of data and for this dataset, ideally it needs to be update once daily\n",
    "\n",
    "* If the data increased by 100x , spark can do it comfortably and what i would do is offload this data into a data lake(S3) in redshift or Azure data lake , transform the data using an EMR cluster in aws or a Synapse Spark cluster in azrue ,the only load the warm and hot data into a reshift datawarehouse or synapse dedicated pool.\n",
    "\n",
    "\n",
    "* For the daily update on 7am , i would use Apache airflow to schedual the pipelins for ease.\n",
    "\n",
    "* If we started using AWS redshift or Azure Synapse, the data can be easily accessed by 100s of peeople and BI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
